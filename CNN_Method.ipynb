{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import skimage.morphology\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#first we get all the frames from the video\n",
    "img_array = []\n",
    "cap = cv2.VideoCapture('../data/robot_parcours_1.avi')\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error opening video stream or file\")\n",
    "while(cap.isOpened()):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    img_array.append(frame)\n",
    "    if ret != True: \n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "#We create a list for the frames of the output video\n",
    "img_out=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We take the first frame to analyze it \n",
    "imtoan=img_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows,cols=imtoan.shape[:2]\n",
    "#M=cv2.getRotationMatrix2D((rows/2,cols/2),20,1)\n",
    "#imtoan=cv2.warpAffine(imtoan,M,(cols,rows))\n",
    "#imgplot = plt.imshow(imtoan)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we find the center of the red arrow by isolating it by color\n",
    "hsv=cv2.cvtColor(imtoan,cv2.COLOR_BGR2HSV)\n",
    "lower_range=np.array([0,100,40])\n",
    "upper_range=np.array([300,300,350])\n",
    "\n",
    "mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    "res = cv2.bitwise_and(imtoan,imtoan, mask= mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do opening to remove small feature appearing in red\n",
    "opening=skimage.morphology.area_opening(mask,area_threshold=200, connectivity=1);\n",
    "\n",
    "\n",
    "#plt.title('Opening of Thresholding ({} px, {} px)'.format(len(opening), len(opening[0])))\n",
    "#plt.imshow(opening);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find contours in the image in the opening to localize the arrow\n",
    "ctrs, hier = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get the rectangle contouring the arrow to get its center\n",
    "rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "p=math.floor(rects[0][2]/2)\n",
    "s=math.floor(rects[0][3]/2)\n",
    "fleche=[rects[0][0]+p,rects[0][1]+s]\n",
    "pointe=np.array([[rects[0][0]+p,rects[0][1]+s]])\n",
    "#image=cv2.drawContours(imtoan,[pointe] , 0, (0,255,0), 5)\n",
    "   \n",
    "#cv2.imshow(\"Resulting Image with Rectangular ROIs\", imtoan)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = imtoan.copy()\n",
    "\n",
    "# Convert to grayscale and apply Gaussian filtering the first frame\n",
    "im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "im_gray = cv2.GaussianBlur(im_gray, (5, 5), 0)\n",
    "afleche=(fleche[0],fleche[1])\n",
    "\n",
    "\n",
    "# Threshold the image\n",
    "ret, im_th = cv2.threshold(im_gray, 90, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Find contours in the image\n",
    "ctrs, hier = cv2.findContours(im_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get rectangles contains each contour\n",
    "rects = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "\n",
    "\n",
    "#We isolate the contour of each operator and merge the contours next to each other \n",
    "for ind1,j in enumerate(rects):\n",
    "    for ind2,i in enumerate(rects):\n",
    "        if(i[0]!=j[0] and i[1]!=j[1] and j[2]>1 and j[3]>1 and i[3]>1 and i[2]>1):\n",
    "            dist=math.sqrt(((j[0]-i[0])**2)+((j[1]-i[1])**2))\n",
    "            distf=math.sqrt(((fleche[0]-i[0])**2)+((fleche[1]-i[1])**2))\n",
    "            if (distf<70):\n",
    "                rects.remove(i)\n",
    "            iteml1=list(i)\n",
    "            iteml2=list(j)\n",
    "            if(dist<15):\n",
    "                #j[0]=(j[0]+i[0])/2\n",
    "                #j[1]=(j[1]+i[1])/2\n",
    "                #j[2]=j[2]+abs(j[0]-i[0])\n",
    "                #j[3]=j[3]+abs(j[1]-i[1])\n",
    "                if (j[0]<i[0]):\n",
    "                    iteml1[0]=j[0]\n",
    "                else:\n",
    "                    iteml1[0]=i[0]\n",
    "                    \n",
    "                if (j[1]<i[1]):\n",
    "                    iteml1[1]=j[1]\n",
    "                else:\n",
    "                    iteml1[1]=i[1]\n",
    "                iteml1[2]=20\n",
    "                #int((j[2]+i[2])/2)\n",
    "                iteml1[3]=20\n",
    "                #int((j[3]+i[3])/2)\n",
    "                item=tuple(iteml1)\n",
    "                rects[ind1]=item\n",
    "                rects.remove(i)\n",
    "\n",
    "#We remove some invariance we have\n",
    "rects = [rect for rect in rects if (rect[2]<40 and rect[3]<40 and rect[2]>8 and rect[3]>8 and rect[1]<400 and rect[0]>100) ]\n",
    "        \n",
    "#From these rectangles we create images 28x28 to analyze \n",
    "lin=[]\n",
    "for rect in rects:\n",
    "    cv2.rectangle(im, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    # Make the rectangular region around the digit\n",
    "    leng = int(rect[3] * 1.6)\n",
    "    pt1 = int(rect[1] + rect[3] // 2 - leng // 2)\n",
    "    pt2 = int(rect[0] + rect[2] // 2 - leng // 2)\n",
    "    roi = im_th[pt1:pt1+leng, pt2:pt2+leng]\n",
    "    # Resize the image\n",
    "    roi = cv2.resize(roi, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    roi = cv2.dilate(roi, np.ones((2,2),np.uint8))\n",
    "    lin.append(roi.tolist())\n",
    "\n",
    "#cv2.imshow(\"Resulting Image with Rectangular ROIs\", im)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We load our Convolutionnal Neural Network Classifier\n",
    "filename = 'digits_cnn2-Copy2.joblib.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\JambonEmmental\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "clf = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vu=[]\n",
    "#We perform our classifier on the images to get their labels\n",
    "#If we dont sufficient results, we rotate the images\n",
    "for i in lin:\n",
    "    best=0\n",
    "    num=0\n",
    "    k=0\n",
    "    while(best<0.8):\n",
    "        rows,cols=np.array(i).shape\n",
    "        M=cv2.getRotationMatrix2D((rows/2,cols/2),k,1)\n",
    "        f=np.array(i,np.uint8)\n",
    "        v=cv2.warpAffine(f,M,(cols,rows))\n",
    "        j=np.array([v.tolist()])\n",
    "        j = j.reshape((j.shape[0], 28, 28, 1)).astype('float32')\n",
    "        j=j/255\n",
    "        res=clf.predict(j)\n",
    "        for c,value in enumerate(res[0],0):\n",
    "            if(value>best):\n",
    "                best=value\n",
    "                num=c\n",
    "            if(c==11 and value>0.1):\n",
    "                best=1\n",
    "                num=c\n",
    "        k=k+2\n",
    "    vu.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(lin[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We print the number to show that we identfied them\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX  \n",
    "fontScale = 1   \n",
    "color = (255, 0, 0)  \n",
    "thickness = 2\n",
    "results=['0','1','2','3','4','5','6','7','8','6','+','-','/','*','=']\n",
    "for c,rect in enumerate(rects,0):\n",
    "    # Using cv2.putText() method \n",
    "    image = cv2.putText(im, results[vu[c]], (rect[0],rect[1]), font,  \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "#cv2.imshow('Image', image) \n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=15\n",
    "showr=[]\n",
    "showp=[]\n",
    "eq=''\n",
    "showp.append((fleche[0],fleche[1]))\n",
    "#We now take all the remaining frames and do the same to identify the arrow \n",
    "#If the the arrow is next to a number, he crosses it and we register that \n",
    "#We write at the same time the equation at the bottom\n",
    "for i in range(1,len(img_array)-1):\n",
    "    hsv=cv2.cvtColor(img_array[i],cv2.COLOR_BGR2HSV)\n",
    "    lower_range=np.array([0,100,40])\n",
    "    upper_range=np.array([300,300,350])\n",
    " \n",
    "    mask = cv2.inRange(hsv, lower_range, upper_range)\n",
    "    res = cv2.bitwise_and(imtoan,imtoan, mask= mask)\n",
    "    opening=skimage.morphology.area_opening(mask,area_threshold=200, connectivity=1);\n",
    "    # Find contours in the image\n",
    "    ctrs, hier = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Get rectangles contains each contour\n",
    "    rec = [cv2.boundingRect(ctr) for ctr in ctrs]\n",
    "    p=math.floor(rec[0][2]/2)\n",
    "    s=math.floor(rec[0][3]/2)\n",
    "    fleche=[rec[0][0]+p,rec[0][1]+s]\n",
    "    showp.append((fleche[0],fleche[1]))\n",
    "    for a in range(len(showp)-1):\n",
    "        image = cv2.line(img_array[i], showp[a], showp[a+1], (0,0,255), thickness, cv2.LINE_AA)\n",
    "    \n",
    "    for rect in rects:\n",
    "        image = cv2.rectangle(image, (rect[0], rect[1]), (rect[0] + rect[2], rect[1] + rect[3]), (0, 255, 0), 3) \n",
    "    \n",
    "    for c,rect in enumerate(rects,0):\n",
    "        # Using cv2.putText() method \n",
    "        image = cv2.putText(image, results[vu[c]], (rect[0],rect[1]), font,  \n",
    "                       fontScale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "    for c,rect in enumerate(rects):\n",
    "        distf=math.sqrt(((fleche[0]-rect[0])**2)+((fleche[1]-rect[1])**2))\n",
    "        if(distf<30 and pr!=c):\n",
    "            showr.append(results[vu[c]])\n",
    "            if (vu[c]!=14):\n",
    "                eq=eq+results[vu[c]]\n",
    "            pr=c\n",
    "            \n",
    "    \n",
    "    k=50\n",
    "    for b in showr:\n",
    "        image = cv2.putText(image, b, (k,image.shape[0]-30), font,  \n",
    "                           fontScale, color, thickness, cv2.LINE_AA)\n",
    "        k+=30\n",
    "    if (i==len(img_array)-2):\n",
    "        image = cv2.putText(image, str(eval(eq)), (k,image.shape[0]-30), font,  \n",
    "                           fontScale, color, thickness, cv2.LINE_AA)\n",
    "        k+=30\n",
    "        \n",
    "    img_out.append(image.copy())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "height, width, layers = img_array[0].shape\n",
    "size = (width,height)\n",
    "out = cv2.VideoWriter('project.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    " \n",
    "for i in range(len(img_out)):\n",
    "    out.write(img_out[i])\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
